{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12 - Neural Networks image recognition\n",
    "Use both MLNN and the ConvNet to solve the following problem.\n",
    "\n",
    "1. Add random noise (i.e. `np.random.normal`) to the images in training and testing. Make sure each image gets a different noise feature added to it. Inspect by printing out an image. \n",
    "2. Compare the loss/accuracy (train, val) after N epochs for both MLNN and ConvNet with and without noise. \n",
    "3. Vary the amount of noise (multiply `np.random.normal` by a factor) and keep track of the accuracy and loss (for training and validation) and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_noise10 = x_train + np.random.normal(0, 255*.10, x_train.shape)\n",
    "x_test_noise10 = x_test + np.random.normal(0, 255*.10, x_test.shape)\n",
    "\n",
    "x_train_noise15 = x_train + np.random.normal(0, 255*.15, x_train.shape)\n",
    "x_test_noise15 = x_test + np.random.normal(0, 255*.15, x_test.shape)\n",
    "\n",
    "x_train_noise20 = x_train + np.random.normal(0, 255*.20, x_train.shape)\n",
    "x_test_noise20 = x_test + np.random.normal(0, 255*.20, x_test.shape)\n",
    "\n",
    "x_train_noise50 = x_train + np.random.normal(0, 255*.50, x_train.shape)\n",
    "x_test_noise50 = x_test + np.random.normal(0, 255*.50, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.2420 - accuracy: 0.9265 - val_loss: 0.0950 - val_accuracy: 0.9700\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1022 - accuracy: 0.9696 - val_loss: 0.0842 - val_accuracy: 0.9734\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0763 - accuracy: 0.9772 - val_loss: 0.0742 - val_accuracy: 0.9783\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 0.1013 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0505 - accuracy: 0.9850 - val_loss: 0.0745 - val_accuracy: 0.9796\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0442 - accuracy: 0.9871 - val_loss: 0.0749 - val_accuracy: 0.9799\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.0862 - val_accuracy: 0.9811\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.0734 - val_accuracy: 0.9840\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0797 - val_accuracy: 0.9830\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0843 - val_accuracy: 0.9825\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.0900 - val_accuracy: 0.9843\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.0914 - val_accuracy: 0.9826\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0984 - val_accuracy: 0.9816\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.1053 - val_accuracy: 0.9825\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.1096 - val_accuracy: 0.9827\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0207 - accuracy: 0.9946 - val_loss: 0.1252 - val_accuracy: 0.9820\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.1305 - val_accuracy: 0.9818\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.1170 - val_accuracy: 0.9824\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.1086 - val_accuracy: 0.9836\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.1388 - val_accuracy: 0.9835\n",
      "Test loss: 0.13880014419555664\n",
      "Test accuracy: 0.9835000038146973\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_nn = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_nn[0])\n",
    "print('Test accuracy:', score_nn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 3.8833 - accuracy: 0.1090 - val_loss: 2.3022 - val_accuracy: 0.1145\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.3060 - accuracy: 0.1167 - val_loss: 2.3069 - val_accuracy: 0.1119\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2923 - accuracy: 0.1225 - val_loss: 2.3038 - val_accuracy: 0.1136\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2827 - accuracy: 0.1265 - val_loss: 2.3095 - val_accuracy: 0.1130\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2728 - accuracy: 0.1303 - val_loss: 2.3025 - val_accuracy: 0.1132\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2694 - accuracy: 0.1336 - val_loss: 2.3037 - val_accuracy: 0.1126\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2644 - accuracy: 0.1360 - val_loss: 2.3047 - val_accuracy: 0.1134\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2627 - accuracy: 0.1377 - val_loss: 2.3022 - val_accuracy: 0.1133\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2606 - accuracy: 0.1379 - val_loss: 2.3027 - val_accuracy: 0.1137\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2593 - accuracy: 0.1396 - val_loss: 2.3032 - val_accuracy: 0.1129\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2606 - accuracy: 0.1408 - val_loss: 2.3054 - val_accuracy: 0.1129\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2539 - accuracy: 0.1425 - val_loss: 2.3042 - val_accuracy: 0.1134\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2583 - accuracy: 0.1423 - val_loss: 2.3047 - val_accuracy: 0.1136\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2525 - accuracy: 0.1444 - val_loss: 2.3042 - val_accuracy: 0.1137\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2529 - accuracy: 0.1440 - val_loss: 2.3048 - val_accuracy: 0.1133\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2508 - accuracy: 0.1454 - val_loss: 2.3098 - val_accuracy: 0.1129\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2494 - accuracy: 0.1456 - val_loss: 2.3095 - val_accuracy: 0.1131\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2513 - accuracy: 0.1451 - val_loss: 2.3055 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2513 - accuracy: 0.1472 - val_loss: 2.3069 - val_accuracy: 0.1131\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2538 - accuracy: 0.1460 - val_loss: 2.3062 - val_accuracy: 0.1128\n",
      "Test loss: 2.306216239929199\n",
      "Test accuracy: 0.1128000020980835\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise10, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise10, y_test))\n",
    "score_nn10 = model.evaluate(x_test_noise10, y_test, verbose=0)\n",
    "print('Test loss:', score_nn10[0])\n",
    "print('Test accuracy:', score_nn10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 4.8214 - accuracy: 0.1085 - val_loss: 2.3049 - val_accuracy: 0.1130\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3061 - accuracy: 0.1163 - val_loss: 2.3020 - val_accuracy: 0.1138\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2963 - accuracy: 0.1184 - val_loss: 2.3022 - val_accuracy: 0.1134\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2953 - accuracy: 0.1213 - val_loss: 2.3032 - val_accuracy: 0.1133\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2874 - accuracy: 0.1230 - val_loss: 2.3029 - val_accuracy: 0.1134\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2867 - accuracy: 0.1239 - val_loss: 2.3024 - val_accuracy: 0.1138\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2862 - accuracy: 0.1256 - val_loss: 2.3015 - val_accuracy: 0.1137\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2831 - accuracy: 0.1268 - val_loss: 2.3043 - val_accuracy: 0.1134\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2812 - accuracy: 0.1275 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2810 - accuracy: 0.1287 - val_loss: 2.3032 - val_accuracy: 0.1133\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2791 - accuracy: 0.1294 - val_loss: 2.3016 - val_accuracy: 0.1137\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2751 - accuracy: 0.1304 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2756 - accuracy: 0.1309 - val_loss: 2.3026 - val_accuracy: 0.1135\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2732 - accuracy: 0.1319 - val_loss: 2.3038 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2714 - accuracy: 0.1321 - val_loss: 2.3029 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2689 - accuracy: 0.1328 - val_loss: 2.3053 - val_accuracy: 0.1133\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2706 - accuracy: 0.1335 - val_loss: 2.3041 - val_accuracy: 0.1139\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2710 - accuracy: 0.1338 - val_loss: 2.3035 - val_accuracy: 0.1132\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2679 - accuracy: 0.1342 - val_loss: 2.3016 - val_accuracy: 0.1136\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2681 - accuracy: 0.1345 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Test loss: 2.301741123199463\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise15, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise15, y_test))\n",
    "score_nn15 = model.evaluate(x_test_noise15, y_test, verbose=0)\n",
    "print('Test loss:', score_nn15[0])\n",
    "print('Test accuracy:', score_nn15[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 5.9826 - accuracy: 0.1077 - val_loss: 2.3026 - val_accuracy: 0.1138\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3088 - accuracy: 0.1151 - val_loss: 2.3059 - val_accuracy: 0.1133\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.3020 - accuracy: 0.1174 - val_loss: 2.3051 - val_accuracy: 0.1135\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2957 - accuracy: 0.1189 - val_loss: 2.3022 - val_accuracy: 0.1134\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2964 - accuracy: 0.1201 - val_loss: 2.3021 - val_accuracy: 0.1140\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 2.2946 - accuracy: 0.1204 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2886 - accuracy: 0.1218 - val_loss: 2.3018 - val_accuracy: 0.1134\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2908 - accuracy: 0.1222 - val_loss: 2.3019 - val_accuracy: 0.1133\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2884 - accuracy: 0.1230 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2875 - accuracy: 0.1238 - val_loss: 2.3013 - val_accuracy: 0.1137\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2865 - accuracy: 0.1241 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2856 - accuracy: 0.1248 - val_loss: 2.3017 - val_accuracy: 0.1136\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2829 - accuracy: 0.1252 - val_loss: 2.3021 - val_accuracy: 0.1137\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2838 - accuracy: 0.1257 - val_loss: 2.3019 - val_accuracy: 0.1137\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2806 - accuracy: 0.1262 - val_loss: 2.3017 - val_accuracy: 0.1134\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2808 - accuracy: 0.1265 - val_loss: 2.3040 - val_accuracy: 0.1133\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2826 - accuracy: 0.1268 - val_loss: 2.3057 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2791 - accuracy: 0.1270 - val_loss: 2.3025 - val_accuracy: 0.1137\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2760 - accuracy: 0.1279 - val_loss: 2.3046 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2789 - accuracy: 0.1276 - val_loss: 2.3024 - val_accuracy: 0.1138\n",
      "Test loss: 2.3023934364318848\n",
      "Test accuracy: 0.11379999667406082\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise20, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise20, y_test))\n",
    "score_nn20 = model.evaluate(x_test_noise20, y_test, verbose=0)\n",
    "print('Test loss:', score_nn20[0])\n",
    "print('Test accuracy:', score_nn20[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 10.7068 - accuracy: 0.1089 - val_loss: 2.3028 - val_accuracy: 0.1133\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3158 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3138 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.3077 - accuracy: 0.1157 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.3072 - accuracy: 0.1160 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3066 - accuracy: 0.1163 - val_loss: 2.3015 - val_accuracy: 0.1134\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3064 - accuracy: 0.1164 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.3032 - accuracy: 0.1172 - val_loss: 2.3021 - val_accuracy: 0.1134\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3020 - accuracy: 0.1172 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.3021 - accuracy: 0.1170 - val_loss: 2.3007 - val_accuracy: 0.1137\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2985 - accuracy: 0.1173 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.3007 - accuracy: 0.1176 - val_loss: 2.3016 - val_accuracy: 0.1134\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2982 - accuracy: 0.1178 - val_loss: 2.3010 - val_accuracy: 0.1136\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.3017 - accuracy: 0.1177 - val_loss: 2.3007 - val_accuracy: 0.1138\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2959 - accuracy: 0.1181 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2938 - accuracy: 0.1180 - val_loss: 2.3016 - val_accuracy: 0.1134\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 2.2947 - accuracy: 0.1179 - val_loss: 2.3012 - val_accuracy: 0.1136\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2973 - accuracy: 0.1185 - val_loss: 2.3015 - val_accuracy: 0.1135- l\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 2.2946 - accuracy: 0.1186 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 2.2968 - accuracy: 0.1183 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010566234588623\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise50, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise50, y_test))\n",
    "score_nn50 = model.evaluate(x_test_noise50, y_test, verbose=0)\n",
    "print('Test loss:', score_nn50[0])\n",
    "print('Test accuracy:', score_nn50[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.2752 - accuracy: 0.1705 - val_loss: 2.2320 - val_accuracy: 0.3669\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 115s 246ms/step - loss: 2.2066 - accuracy: 0.2875 - val_loss: 2.1504 - val_accuracy: 0.4971\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 2.1202 - accuracy: 0.3871 - val_loss: 2.0392 - val_accuracy: 0.6126\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.0047 - accuracy: 0.4634 - val_loss: 1.8926 - val_accuracy: 0.6838\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 117s 250ms/step - loss: 1.8616 - accuracy: 0.5206 - val_loss: 1.7147 - val_accuracy: 0.7254\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 1.6990 - accuracy: 0.5627 - val_loss: 1.5176 - val_accuracy: 0.7540\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 1.5319 - accuracy: 0.5975 - val_loss: 1.3216 - val_accuracy: 0.7777\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 117s 250ms/step - loss: 1.3794 - accuracy: 0.6245 - val_loss: 1.1469 - val_accuracy: 0.7989\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 1.2448 - accuracy: 0.6525 - val_loss: 1.0017 - val_accuracy: 0.8154\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 115s 246ms/step - loss: 1.1344 - accuracy: 0.6745 - val_loss: 0.8867 - val_accuracy: 0.8284\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 117s 250ms/step - loss: 1.0516 - accuracy: 0.6927 - val_loss: 0.7986 - val_accuracy: 0.8375\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 0.9770 - accuracy: 0.7114 - val_loss: 0.7276 - val_accuracy: 0.8449\n",
      "Test loss: 0.7276210188865662\n",
      "Test accuracy: 0.8449000120162964\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score_cn = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_cn[0])\n",
    "print('Test accuracy:', score_cn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise10 = x_train + np.random.normal(0, 255*.10, x_train.shape)\n",
    "x_test_noise10 = x_test + np.random.normal(0, 255*.10, x_test.shape)\n",
    "\n",
    "x_train_noise15 = x_train + np.random.normal(0, 255*.15, x_train.shape)\n",
    "x_test_noise15 = x_test + np.random.normal(0, 255*.15, x_test.shape)\n",
    "\n",
    "x_train_noise20 = x_train + np.random.normal(0, 255*.20, x_train.shape)\n",
    "x_test_noise20 = x_test + np.random.normal(0, 255*.20, x_test.shape)\n",
    "\n",
    "x_train_noise50 = x_train + np.random.normal(0, 255*.50, x_train.shape)\n",
    "x_test_noise50 = x_test + np.random.normal(0, 255*.50, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 118s 251ms/step - loss: 7.1525 - accuracy: 0.1005 - val_loss: 2.4515 - val_accuracy: 0.1001\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 118s 253ms/step - loss: 2.8377 - accuracy: 0.0994 - val_loss: 2.3031 - val_accuracy: 0.1003\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 118s 252ms/step - loss: 2.3872 - accuracy: 0.1020 - val_loss: 2.3025 - val_accuracy: 0.1008\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 118s 252ms/step - loss: 2.3355 - accuracy: 0.1011 - val_loss: 2.3025 - val_accuracy: 0.1010\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 122s 260ms/step - loss: 2.3204 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.1012\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 118s 251ms/step - loss: 2.3155 - accuracy: 0.1072 - val_loss: 2.3025 - val_accuracy: 0.1136\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 118s 251ms/step - loss: 2.3111 - accuracy: 0.1111 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.3099 - accuracy: 0.1116 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.3088 - accuracy: 0.1114 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.3077 - accuracy: 0.1120 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 117s 250ms/step - loss: 2.3068 - accuracy: 0.1125 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 119s 254ms/step - loss: 2.3066 - accuracy: 0.1120 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Test loss: 2.302523612976074\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_noise10, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_noise10, y_test))\n",
    "score_cn10 = model.evaluate(x_test_noise10, y_test, verbose=0)\n",
    "print('Test loss:', score_cn10[0])\n",
    "print('Test accuracy:', score_cn10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 121s 259ms/step - loss: 9.6275 - accuracy: 0.0999 - val_loss: 2.6429 - val_accuracy: 0.0973\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 3.3043 - accuracy: 0.0988 - val_loss: 2.3052 - val_accuracy: 0.0986\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 2.4603 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1141\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 122s 260ms/step - loss: 2.3572 - accuracy: 0.1084 - val_loss: 2.3026 - val_accuracy: 0.1135\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 120s 256ms/step - loss: 2.3325 - accuracy: 0.1104 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 120s 255ms/step - loss: 2.3234 - accuracy: 0.1095 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 131s 279ms/step - loss: 2.3180 - accuracy: 0.1106 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 122s 261ms/step - loss: 2.3152 - accuracy: 0.1111 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 119s 254ms/step - loss: 2.3120 - accuracy: 0.1116 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 118s 252ms/step - loss: 2.3106 - accuracy: 0.1123 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 118s 252ms/step - loss: 2.3085 - accuracy: 0.1122 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 118s 251ms/step - loss: 2.3089 - accuracy: 0.1115 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Test loss: 2.3025200366973877\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_noise15, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_noise15, y_test))\n",
    "score_cn15 = model.evaluate(x_test_noise15, y_test, verbose=0)\n",
    "print('Test loss:', score_cn15[0])\n",
    "print('Test accuracy:', score_cn15[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 119s 253ms/step - loss: 14.6517 - accuracy: 0.1010 - val_loss: 3.0254 - val_accuracy: 0.1003\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 120s 256ms/step - loss: 3.9864 - accuracy: 0.0999 - val_loss: 2.3054 - val_accuracy: 0.1042\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 121s 258ms/step - loss: 2.5208 - accuracy: 0.1022 - val_loss: 2.3026 - val_accuracy: 0.1023\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 120s 255ms/step - loss: 2.3815 - accuracy: 0.1032 - val_loss: 2.3026 - val_accuracy: 0.1026\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 120s 255ms/step - loss: 2.3432 - accuracy: 0.1046 - val_loss: 2.3026 - val_accuracy: 0.1026\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 136s 290ms/step - loss: 2.3284 - accuracy: 0.1036 - val_loss: 2.3026 - val_accuracy: 0.1026\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 128s 272ms/step - loss: 2.3200 - accuracy: 0.1041 - val_loss: 2.3026 - val_accuracy: 0.1027\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 133s 284ms/step - loss: 2.3191 - accuracy: 0.1038 - val_loss: 2.3026 - val_accuracy: 0.1027\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.3160 - accuracy: 0.1042 - val_loss: 2.3025 - val_accuracy: 0.1027\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 2.3134 - accuracy: 0.1041 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 119s 253ms/step - loss: 2.3119 - accuracy: 0.1116 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 2.3105 - accuracy: 0.1117 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Test loss: 2.3025314807891846\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_noise20, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_noise20, y_test))\n",
    "score_cn20 = model.evaluate(x_test_noise20, y_test, verbose=0)\n",
    "print('Test loss:', score_cn20[0])\n",
    "print('Test accuracy:', score_cn20[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 33.0727 - accuracy: 0.1005 - val_loss: 4.2993 - val_accuracy: 0.0938\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 6.8540 - accuracy: 0.1007 - val_loss: 2.3068 - val_accuracy: 0.1009\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 116s 246ms/step - loss: 2.8969 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1135\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 115s 245ms/step - loss: 2.4970 - accuracy: 0.1098 - val_loss: 2.3025 - val_accuracy: 0.1136\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 2.4137 - accuracy: 0.1113 - val_loss: 2.3026 - val_accuracy: 0.1135\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 115s 246ms/step - loss: 2.3721 - accuracy: 0.1111 - val_loss: 2.3026 - val_accuracy: 0.1135\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 2.3493 - accuracy: 0.1119 - val_loss: 2.3026 - val_accuracy: 0.1135\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 115s 246ms/step - loss: 2.3419 - accuracy: 0.1115 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 115s 245ms/step - loss: 2.3364 - accuracy: 0.1122 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 2.3261 - accuracy: 0.1119 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 115s 246ms/step - loss: 2.3237 - accuracy: 0.1124 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 115s 245ms/step - loss: 2.3222 - accuracy: 0.1117 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Test loss: 2.3025271892547607\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_noise50, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_noise50, y_test))\n",
    "score_cn50 = model.evaluate(x_test_noise50, y_test, verbose=0)\n",
    "print('Test loss:', score_cn50[0])\n",
    "print('Test accuracy:', score_cn50[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing Loss for Multi Layer Neural Network vs ConvNet with Noise\n",
    "MLNN model has lower loss. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23283a866c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_losses = np.array([score_nn[0], score_nn10[0], score_nn15[0], score_nn20[0], score_nn50[0]])\n",
    "cn_losses = np.array([score_cn[0], score_cn10[0], score_cn15[0], score_cn20[0], score_cn50[0]])\n",
    "plt.plot(nn_losses, label='NN Losses', color='b')\n",
    "plt.plot(cn_losses, label='CN Losses', color='orange')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13880014, 2.30621624, 2.30174112, 2.30239344, 2.30105662])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72762102, 2.30252361, 2.30252004, 2.30253148, 2.30252719])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing Accurancy for Multi Layer Neural Network vs ConvNet with Noise\n",
    "MLNN model has higher accuracy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23283ad2cc8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXQUdbr/8fcDSQyrgAREAiQikIAQhFxgQIERB8FBHAZEmBGUxPHquIyC+GN09DozR889iAu477ixiQrI6KBcUUfcABcUAogKEpRVdmTN9/dHJTEknaQD3V3dnc/rHI7dVd+ufizoTyrfqnranHOIiEjsq+F3ASIiEhoKdBGROKFAFxGJEwp0EZE4oUAXEYkTCX69cePGjV1aWppfby8iEpOWLVu2zTmXEmidb4GelpbG0qVL/Xp7EZGYZGbry1unKRcRkThRaaCb2dNmtsXMvipnvZnZFDNba2bLzaxL6MsUEZHKBHOEPhUYUMH6gUCbwj9XAo+ceFkiIlJVlc6hO+feM7O0CoZcBDznvB4CH5lZAzNr5pz7MUQ1ikiEHD58mPz8fA4cOOB3KdVecnIyqampJCYmBv2aUJwUbQ5sKPE8v3BZmUA3syvxjuJp2bJlCN5aREIpPz+fevXqkZaWhpn5XU615Zxj+/bt5Ofnk56eHvTrQnFSNNDfesCOX865x51z2c657JSUgFfdiIiPDhw4wCmnnKIw95mZccopp1T5N6VQBHo+0KLE81TghxBsV0R8oDCPDsfz9xCKQJ8HjC682qUHsCuc8+effAJ//Wu4ti4iEruCuWxxOvAh0M7M8s0s18yuMrOrCoe8DnwLrAWeAP4ctmqBpUvhf/8XPv00nO8iIn4xM8aNG1f8fNKkSdxxxx0A3HHHHdSuXZstW7YUr69bt2652/rss88wMxYsWBC2eqNJpYHunBvpnGvmnEt0zqU6555yzj3qnHu0cL1zzl3jnGvtnOvonAvr7Z9/+AMkJ8PTT4fzXUTELyeddBKvvPIK27ZtC7i+cePG3HPPPUFta/r06Zx99tlMnz49lCWWceTIkbBuP1gxd6dogwbw+9/Diy/Czz/7XY2IhFpCQgJXXnkl9913X8D1OTk5zJw5k59++qnC7TjnmD17NlOnTuXNN9885gTjc889R6dOncjKymLUqFEAbN68mSFDhpCVlUVWVhYffPAB69at48wzzyx+XcnfFvr27cstt9xCnz59mDx5Mq+99hrdu3fnrLPO4rzzzmPz5s0A7N27lzFjxtCxY0c6derEyy+/zFNPPcWNN95YvN0nnniCsWPHHtf+Ksm3Xi4nIjcXpk2DOXNg5Ei/qxGJTzfcAJ9/Htptdu4M999f+bhrrrmGTp06cfPNN5dZV7duXXJycpg8eTJ///vfy93G4sWLSU9Pp3Xr1vTt25fXX3+d3//+96xYsYI777yTxYsX07hx4+IfDNdffz19+vTh1Vdf5ejRo+zdu5cdO3ZUWOfOnTt59913AdixYwcfffQRZsaTTz7JxIkTueeee/jnP//JySefzJdfflk8LikpiU6dOjFx4kQSExN55plneOyxxyrfMZWIuSN0gL59IT0dnnrK70pEJBzq16/P6NGjmTJlSsD1119/Pc8++yy7d+8udxvTp09nxIgRAIwYMaJ42uXtt99m2LBhNG7cGIBGjRoVL7/66qsBqFmzJieffHKldV5yySXFj/Pz8zn//PPp2LEjd999NytWrABg4cKFXHPNNcXjGjZsSJ06dTj33HOZP38+q1at4vDhw3Ts2LHS96tMTB6h16gBY8bA7bfDunWgLrwioRfMkXQ43XDDDXTp0oUxY8aUWdegQQP+8Ic/8PDDDwd87dGjR3n55ZeZN28ed955Z/GNOnv27ME5F/QlgQkJCRQUFBQ/L31deJ06dYofX3fddYwdO5bBgwfzzjvvFE/NlPd+V1xxBXfddRcZGRkB/x+PR0weoQNcdhmYwTPP+F2JiIRDo0aNGD58OE+V86v42LFjeeyxxwKekFy4cCFZWVls2LCBdevWsX79eoYOHcqcOXPo168fs2bNYvv27QDFUy79+vXjkUe8VlRHjx5l9+7dNG3alC1btrB9+3YOHjzI/Pnzy613165dNG/eHIBnn322eHn//v158MEHi58XTeN0796dDRs2MG3aNEaGaO44ZgO9ZUvo398L9KNH/a5GRMJh3LhxFV7tMmTIEA4ePFhm3fTp0xkyZMgxy4YOHcq0adPo0KEDt956K3369CErK6v4ZOTkyZNZtGgRHTt2pGvXrqxYsYLExERuv/12unfvzqBBg8jIyCi31jvuuIOLL76Yc845p3g6B+Bvf/sbO3bs4MwzzyQrK4tFixYVrxs+fDi9evWiYcOGVdov5TGvp1bkZWdnuxP9gotZs+CSS2DBAi/cReTE5OXlkZmZ6XcZ1cagQYO48cYb6devX8D1gf4+zGyZcy470PiYPUIHuOgiaNRIJ0dFJLbs3LmTtm3bUqtWrXLD/HjE5EnRIiedBJdeCo8+Ctu3wymn+F2RiEjlGjRowJo1a0K+3Zg+QgfIyYFDh7wbjUREqrOYD/SsLOja1Zt28el0gIhIVIj5QAfvztHly9WwS0Sqt7gI9JEj1bBLRCQuAr1BAxg6VA27ROLBpk2bGDFiBK1bt6Z9+/ZccMEFrFmzhnXr1mFmPPDAA8Vjr732WqZOnVrutrKyskJ2004siItAB2/aZdcuePVVvysRkePlnGPIkCH07duXb775hpUrV3LXXXcVdy5s0qQJkydP5tChQ5VuKy8vj4KCAt577z327dsXtpqjpXUuxFGg9+mjhl0isW7RokUkJiZy1VVXFS/r3Lkz55xzDgApKSn069fvmFvryzNt2jRGjRpF//79mTdvXvHytWvXct5555GVlUWXLl345ptvAJg4cSIdO3YkKyuLCRMmAF6L3KIbILdt20ZaYeOoqVOncvHFF3PhhRfSv39/9u7dS79+/ejSpQsdO3Zk7ty5xe9XulXvnj17SE9P5/DhwwDs3r2btLS04ucnIqavQy+pRg3vEsbbboPvvvPCXUROwLIbYEeI++c27Axdy+/69dVXX9G1a9cKNzFhwgQGDhxITk5OheNmzpzJW2+9xerVq3nwwQeLp17++Mc/MmHCBIYMGcKBAwcoKCjgjTfeYM6cOXz88cfUrl270l7rAB9++CHLly+nUaNGHDlyhFdffZX69euzbds2evToweDBg1m5cmWZVr316tWjb9++/Otf/+J3v/sdM2bMYOjQoSQmJlb6npWJmyN0UMMukeogPT2dbt26MW3atHLHLFmyhJSUFFq1akW/fv349NNP2bFjB3v27GHjxo3FfV6Sk5OpXbs2CxcuZMyYMdSuXRv4paVuRX7zm98Uj3POccstt9CpUyfOO+88Nm7cyObNm8tt1XvFFVfwTGFQPfPMMyHrthg3R+gALVrA+ed7gf4//wM1a/pdkUgMq+BIOlw6dOjA7NmzKx13yy23MGzYMHr37h1w/fTp01m1alXxFMnu3bt5+eWXGT58eMDx5bW4Ldk+t6LWuS+++CJbt25l2bJlJCYmkpaWxoEDB8rdbq9evVi3bh3vvvsuR48ePeZbkU5EXB2hgzftkp8PCxf6XYmIVNW5557LwYMHeeKJJ4qXLVmypPhbgYpkZGTQvn37gO1sCwoKeOmll1i+fDnr1q1j3bp1zJ07l+nTp1O/fn1SU1OZM2cOAAcPHmT//v3079+fp59+mv379wO/tNRNS0tj2bJlABX+oNm1axdNmjQhMTGRRYsWsX79eoByW/UCjB49mpEjR4bs6BziMNAHD/Z6uujkqEjsMTNeffVV3nrrLVq3bk2HDh244447OO2008qMvfXWW8nPzy+z/L333qN58+bFvckBevfuzcqVK/nxxx95/vnnmTJlCp06daJnz55s2rSJAQMGMHjwYLKzs+ncuTOTJk0C4KabbuKRRx6hZ8+e5bbxBW9efunSpWRnZ/Piiy8Wt9ktr1Vv0Wt27NgR0ssqY7p9bnluuAEefhh++AFKtCUWkUqofW7kzJ49m7lz5/L888+XO6Zatc8tT24uHD6shl0iEp2uu+46JkyYwG233RbS7cbVSdEiHTtCdrY37XL99d6VLyIi0aLk3a6hFJdH6OAdpX/5JRSezxCRIPk1DSvHOp6/h7gNdDXsEqm65ORktm/frlD3mXOO7du3k5ycXKXXxeWUC8DJJ8OwYTBtGtxzD9Sq5XdFItEvNTWV/Px8tm7d6ncp1V5ycjKpqalVek3cBjp40y4vvACvvAJ//KPf1YhEv8TERNLVNyNmxeaUy/6y154G0rs3nH66rkkXkeoh9gJ9xV3wWjs4WHnznKKGXYsWQWFDNRGRuBV7gd78Qji6H75+JKjhl13mBXsFPfBFROJC7AV6g47QbCCsmQJHD1Q6PDXVa9g1dSocPRr+8kRE/BJ7gQ7Qfjwc2ALfPRfU8KKGXW+9Fea6RER8FJuB3qQvNOoKefdAQeWH3YMHez1ddHJUROJZbAa6GWSOhz1rYOO8SocnJcGll8LcuVBBwzQRkZgWm4EO0GIo1EmHvLuDGl7UsOuFF8Jcl4iIT2I30GskQMZY2PYhbF1c6fAzz4Ru3bxWALqrWUTiUVCBbmYDzGy1ma01swkB1rc0s0Vm9pmZLTezC0JfagCtx0BSo6CP0nNyvIZdYWrDLiLiq0oD3cxqAg8BA4H2wEgza19q2N+AWc65s4ARwMOhLjSghDrQ9lrInwu7VlU6fMQIr6eLGnaJSDwK5gi9G7DWOfetc+4QMAO4qNQYB9QvfHwy8EPoSqxE22uhZjKsuqfSoSUbdhV+daCISNwIJtCbAxtKPM8vXFbSHcClZpYPvA5cF2hDZnalmS01s6Uh6+aWnALpl3vXpP+8qdLhubmweze8/HJo3l5EJFoEE+iBvu+n9GnFkcBU51wqcAHwvJmV2bZz7nHnXLZzLjslJaXq1ZYncxwUHIbVUyod2rs3tG6taRcRiT/BBHo+0KLE81TKTqnkArMAnHMfAslA5L6eud4Z0OL3Xn+Xw3sqHGrmnRx95x017BKR+BJMoC8B2phZupkl4Z30LH03z/dAPwAzy8QL9Mh2yM8cD4d3wjeV3w5a1LDrmWciUJeISIRUGujOuSPAtcACIA/vapYVZvYPMxtcOGwc8Ccz+wKYDlzuIv0dVo27Q5PesOpeb/qlAs2bw4ABatglIvElqOvQnXOvO+faOudaO+fuLFx2u3NuXuHjlc65Xs65LOdcZ+fcm+EsulyZ42H/Blg/q9KhOTmwcSO86U+lIiIhF7t3igZy2gVQP9O70aiSXxAuvFANu0QkvsRXoFsN7yh95xewqeJeuUlJMGoUzJsH+j5cEYkH8RXoAGl/gFrNgmoHoIZdIhJP4i/Qa54E7f4CmxbCT59VOLRDB+je3Zt2UcMuEYl18RfoAGf8NyTUhbxJlQ7NyYEVK2DJkgjUJSISRvEZ6EkNvFD/fibsW1/hUDXsEpF4EZ+BDt60Cwar7qtwWP36cPHFMH26GnaJSGyL30Cv0wJajYRvnoSDP1U4tKhh1+zZEapNRCQM4jfQAdqPhyP7vB4vFTjnHDjjDE27iEhsi+9Ab9ARmg2ANQ/A0QPlDitq2PXuu7B2bQTrExEJofgOdPBuNDqwGb57vsJho0erYZeIxLb4D/Smv4ZGXb1LGF1BucOaN4eBA72GXUeORK48EZFQif9AN/OO0vesgfzSXX+PlZMDP/yghl0iEpviP9ABWgyFOmmVtgMYNAhSUtSwS0RiU/UI9BoJkDEOtn0AWxeXO0wNu0QkllWPQAdoPQaSGlV6lJ6b682hP1/xOVQRkahTfQI9oQ60vcabR9+1qtxh7dtDjx5q2CUisaf6BDpA22u9boyr7qlwWE4OrFwJn3wSobpEREKgegV6chNIvxy+ew5+3lTusEsugdq1dXJURGJL9Qp0gIyx3pdIr3mg3CFFDbtmzIB9+yJYm4jICah+gV6/DbQYAmsehsN7yx2Wmwt79qhhl4jEjuoX6ACZN8PhnV4nxnKcfTa0aaOGXSISO6pnoDfuDinneL3SCw4HHFLUsOu99+DrryNcn4jIcaiegQ5eO4D938P3L5U7RA27RCSWVN9Ab/5bqJ8JKyeWe8H5aafBBReoYZeIxIbqG+hWAzJvgp1fwKaF5Q7LyYEff4QFCyJYm4jIcai+gQ6Q9keo1azCdgCDBkGTJromXUSiX/UO9JoneV8mvekt+OmzgEMSE7259Ndegy1bIlyfiEgVVO9ABzjjvyGhrvcFGOXIyVHDLhGJfgr0pAZwxpXw/UzYtz7gkMxM+NWv1LBLRKKbAh2g3Q2AedellyMnB/Ly4OOPI1eWiEhVKNAB6rSAViO9O0cP7Qg4RA27RCTaKdCLZN4ER/bB148EXF2vHgwfroZdIhK9FOhFGnaCZufD6ilw9EDAIbm5sHcvvFT+zaUiIr5RoJeUeTMc2AzfBb6cpVcvaNtWDbtEJDop0Etq+mto2MX7RiNXUGZ1UcOu//wH1qzxoT4RkQoEFehmNsDMVpvZWjObUM6Y4Wa20sxWmNm00JYZIWZe067dq2HjawGHjB4NNWuqYZeIRJ9KA93MagIPAQOB9sBIM2tfakwb4K9AL+dcB+CGMNQaGS2HQZ00r2lXAM2aeQ27nn1WDbtEJLoEc4TeDVjrnPvWOXcImAFcVGrMn4CHnHM7AJxzsXuTfI0E72vqtn0AWz8IOKSoYde//x3h2kREKhBMoDcHNpR4nl+4rKS2QFszW2xmH5nZgEAbMrMrzWypmS3dunXr8VUcCa1zIKlRuU27fvtbaNpU16SLSHQJJtAtwLLSN8AnAG2AvsBI4Ekza1DmRc497pzLds5lp6SkVLXWyEmoA22vgfy53nx6KUUNu+bPh82bfahPRCSAYAI9H2hR4nkq8EOAMXOdc4edc98Bq/ECPna1vdbrxph3T8DVatglItEmmEBfArQxs3QzSwJGAPNKjZkD/BrAzBrjTcF8G8pCIy65CaRfBt89Bz9vKrM6IwN69lTDLhGJHpUGunPuCHAtsADIA2Y551aY2T/MbHDhsAXAdjNbCSwCxjvntoer6IjJGAcFh2DNAwFX5+TAqlXw0UcRrktEJABzPh1eZmdnu6VLl/ry3lXyn6GweRFc9D0k1j1m1Z493mWMI0bAk0/6VJ+IVCtmtsw5lx1one4UrUzmeK8D4zdlL2kpatg1c6bX40VExE8K9Mo07gEpZ8Oqe6HgcJnVatglItFCgR6MzJth//fwfdnU7tkT2rVTwy4R8Z8CPRjNfwv1M7wbjUqdcyhq2PX++7C67CXrIiIRo0APhtXwvgBjx+ew+f/KrFbDLhGJBgr0YKVdCsmnBmzadeqpXjsANewSET8p0INV8yRo9xfY9JZ3pF5Kbi5s2gSvv+5DbSIiKNCrps1VkFAX8iaVWTVwoNewSydHRcQvCvSqSGoAZ1wJ62fAvvXHrEpMhMsu8xp2bSrbKUBEJOwU6FXV7gbAYNX9ZVaNGQNHj6phl4j4Q4FeVXVaQKsR8M0T3h2kJWRkeF8krYZdIuIHBfrxyBwPR/bB14+UWZWT412P/uGHPtQlItWaAv14NOwEzc6H1VPg6IFjVg0fDnXq6NuMRCTyFOjHK3M8HNgM371wzOK6deGSS9SwS0QiT4F+vJqeCw3PglWTwBUcsyo3F/btg1mzfKpNRKolBfrxMvOadu1eDRtfO2bVr36lhl0iEnkK9BPRchjUSfOadpVg5h2lL17sfaORiEgkKNBPRI0EyLgRti6GrR8cs2rUKK9hl47SRSRSFOgnqnUuJDUqc5R+6qkwaBA89xwcLvu9GCIiIadAP1EJdaDNnyF/Luxec8yq3FzYvFkNu0QkMhToodD2WqiRBKvuOWbxwIHekbqmXUQkEhTooVCrKZx+OXz7LPy8uXhxQoLXsOtf/4Iff/SvPBGpHhTooZIxDgoOwZoHjlmshl0iEikK9FCp3wZSfwdfPwyHf7lFtF07OPtsNewSkfBToIdS+5u9DozfHNvIJScH1qyBDz4o53UiIiGgQA+lxj0g5WxYfR8U/PLlohdf7PV4UcMuEQknBXqoZY73vs3o+5eKFxU17Jo1C/bs8bE2EYlrCvRQaz4I6mdA3sRjJs3VsEtEwk2BHmpWAzJvgh2fw+b/K17co4f3jUaadhGRcFGgh0PapZB8Kqz8pR1AUcOuDz+EvDwfaxORuKVAD4eaJ0G762HTm96ReqFRo7ybjXTnqIiEgwI9XNpcBQl1IW9S8aKmTdWwS0TCR4EeLkkNofWfYP0M76qXQrm5sGWL1w5ARCSUFOjhlHGD999V9xcvGjAAmjXTtIuIhJ4CPZzqtIRWI+GbJ7w7SPmlYdfrr6thl4iElgI93DJvgiP74OtHixcVNex67jkf6xKRuKNAD7eGWXBqf1g9BY4eAKBtWzjnHG/aRQ27RCRUggp0MxtgZqvNbK2ZTahg3DAzc2aWHboS40D7m+HAJvjuheJFRQ27Fi/2sS4RiSuVBrqZ1QQeAgYC7YGRZtY+wLh6wPXAx6EuMuY1PRcangWrJoErANSwS0RCL5gj9G7AWufct865Q8AM4KIA4/4JTAQOhLC++GDmNe3avRo2zgegTh0YMUINu0QkdIIJ9ObAhhLP8wuXFTOzs4AWzrn5FW3IzK40s6VmtnTr1q1VLjamtbwY6rTymnYVys2F/fth5kwf6xKRuBFMoFuAZcWn8sysBnAfMK6yDTnnHnfOZTvnslNSUoKvMh7USICMsbB1MWz9EIDu3SEzU9MuIhIawQR6PtCixPNU4IcSz+sBZwLvmNk6oAcwTydGAzg9x7uDNM9r2lXUsOujj2DlSp9rE5GYF0ygLwHamFm6mSUBI4B5RSudc7ucc42dc2nOuTTgI2Cwc25pWCqOZYl1oc2fIX8O7F4DqGGXiIROpYHunDsCXAssAPKAWc65FWb2DzMbHO4C407b66BGEqy6B4AmTeDCC9WwS0ROXFDXoTvnXnfOtXXOtXbO3Vm47Hbn3LwAY/vq6LwCtZrC6ZfBt8/Cz5sBb9pl61aYX+EpZRGRiulOUT9kjIOCQ7DmAQDOP18Nu0TkxCnQ/VC/LaT+Dr5+GA7vJSEBLr/ca9j1ww+VvlpEJCAFul8yx3sdGL/1DsvHjIGCAjXsEpHjp0D3S8qvIKUXrLoXCo7Qpg307q2GXSJy/BTofsq82fs2o+9fAryGXV9/De+/73NdIhKTFOh+aj4I6md4Nxo5x7BhUK+e7hwVkeOjQPeT1fCueNnxGWx+u7hh10svwe7dfhcnIrFGge639EshuSms9Jp2qWGXiBwvBbrfaiZDu7/Apjdhxxd06wbt22vaRUSqToEeDdpcBQl1IG9SccOujz+GFSv8LkxEYokCPRokNYTWf4L102Hf92rYJSLHRYEeLTJu9P676n5SUmDwYHj+eTh0yN+yRCR2KNCjRZ2W0GoEfPMEHNqhhl0iUmUK9GiSOR6O7IWvH6V/fzjtNE27iEjwFOjRpGEWnNofVk8hwQ5y+eXwxhuwcaPfhYlILFCgR5v24+HAJlj3ghp2iUiVKNCjTdN+0LAz5N3NGa0L6NNHDbtEJDgK9Ghj5jXt2r0aNs4nJwfWroX33vO7MBGJdgr0aNTyYqjTCvLuLm7YpZOjIlIZBXo0qpEA7W6Ere9Te9+HjBzpNezatcvvwkQkminQo1XrXO8O0ry7yc2Fn39Wwy4RqZgCPVol1oU2f4b8OfxXuzV06KCGXSJSMQV6NGt7HdRIwlbfS24ufPIJfPWV30WJSLRSoEezWk0hfTR8O5VRF28mMVEnR0WkfAr0aJc5DgoO0Xj7g2rYJSIVUqBHu/rtIPUi+PohrszZy7Zt8NprfhclItFIgR4LMsfDoR2cl/40zZtr2kVEAlOgx4KUnpDSixpr7iPn8iP8+99q2CUiZSnQY0XmeNi3jmsGz6agAKZO9bsgEYk2CvRY0fxCqN+Optsn0rev4+mnvU6MIiJFFOixwmpAxk2w4zNuyXmbb79Vwy4ROZYCPZakXwrJTTm32d3Ur6+ToyJyLAV6LKmZDO2up+aWBdx0xXJmz1bDLhH5hQI91rS5GhLqcHXfu/n5Z5gxw++CRCRaKNBjTVJDaP0nTtk7g/N6blDDLhEppkCPRRk3YDj+d8z9LFkCX37pd0EiEg2CCnQzG2Bmq81srZlNCLB+rJmtNLPlZvZ/ZtYq9KVKsTqtoOUlnFXvcRqfvFMnR0UECCLQzawm8BAwEGgPjDSz9qWGfQZkO+c6AbOBiaEuVEppP54aR/dy/zWPqmGXiADBHaF3A9Y65751zh0CZgAXlRzgnFvknNtf+PQjIDW0ZUoZDTvDqb9h6JmT2bPrIPPm+V2QiPgtmEBvDmwo8Ty/cFl5coE3Aq0wsyvNbKmZLd26dWvwVUpgmeNJdpu47sIXdHJURIIKdAuwzAUcaHYpkA3cHWi9c+5x51y2cy47JSUl+ColsFPPg4ad+X8XTuLNNwvYsKHyl4hI/Aom0POBFiWepwI/lB5kZucBtwKDnXMHQ1OeVMgMMseTctIqLsj6F88+63dBIuKnYAJ9CdDGzNLNLAkYARwzY2tmZwGP4YX5ltCXKeVqeTHUbsmdl07kmWfUsEukOqs00J1zR4BrgQVAHjDLObfCzP5hZoMLh90N1AVeMrPPzUyn6CKlRiJkjKXTqe+TUuMj3n3X74JExC/mXMDp8LDLzs52S5cu9eW9487hvbg5LXntk1/z0qaXef55vwsSkXAxs2XOuexA63SnaDxIrIu1vZpBnV/l8/+sYedOvwsSET8o0ONF2+ugRhLX9LtXDbtEqikFeryodSp2+mjG9JnKK9N0XlqkOlKgxxHLHEdSzUOc3eRBli/3uxoRiTQFejyp347DTQdzTf+HeGHqPr+rEZEIU6DHmaSsmzml7k/U+O5pDur2LpFqRYEeb1J6siOhJ//d515em3vE72pEJIIU6HGofvfxpDdZx9dvz/a7FBGJIAV6HKrZcjDbDralf4u72fC9PzeOiUjkKdDjkdXAZdxE170AT1MAAAWXSURBVPRPeWfWIr+rEZEIUaDHqZRuo/hpf1Na7p2ohl0i1YQCPV7VTOb7WtfTp+0Clryli9JFqoMEvwuQ8Gk36Gr2vnwXh76YBOc/53c5cSNQP7vSy6r6PBTb8KuuQCzA1+KUXlbV535tI1TvGwkK9DhW6+SGvL39Cs5NnUzBiy+UP1DnTUOu9OfZp8+3REjpj1BlH6n3Dz5M79yrQl6HAj3Otb7oNl568RTMHfYWWIn/2DGLgnpelbEheZ+iRVU4Igrl2MqWV2VMJLYRqTor/AkVxAFCZUf5wfwWEIlthOt9mpzVtfIXHQcFepxr1fYUWv39Nr/LEJEI0ElREZE4oUAXEYkTCnQRkTihQBcRiRMKdBGROKFAFxGJEwp0EZE4oUAXEYkT5oK5zSkcb2y2FVh/nC9vDGwLYTmhorqqRnVVXbTWprqq5kTqauWcSwm0wrdAPxFmttQ5l+13HaWprqpRXVUXrbWprqoJV12achERiRMKdBGROBGrgf643wWUQ3VVjeqqumitTXVVTVjqisk5dBERKStWj9BFRKQUBbqISJyI6kA3swFmttrM1prZhADrTzKzmYXrPzaztCip63Iz22pmnxf+uSJCdT1tZlvM7Kty1puZTSmse7mZdYmSuvqa2a4S++v2CNTUwswWmVmema0ws78EGBPx/RVkXX7sr2Qz+8TMviis6+8BxkT88xhkXb58Hgvfu6aZfWZm8wOsC/3+cs5F5R+gJvANcDqQBHwBtC815s/Ao4WPRwAzo6Suy4EHfdhnvYEuwFflrL8AeAPvC8R6AB9HSV19gfkR3lfNgC6Fj+sBawL8PUZ8fwVZlx/7y4C6hY8TgY+BHqXG+PF5DKYuXz6Phe89FpgW6O8rHPsrmo/QuwFrnXPfOucOATOAi0qNuQh4tvDxbKCfWdi/bzuYunzhnHsP+KmCIRcBzznPR0ADM2sWBXVFnHPuR+fcp4WP9wB5QPNSwyK+v4KsK+IK98HewqeJhX9KX1ER8c9jkHX5wsxSgd8CT5YzJOT7K5oDvTmwocTzfMr+wy4e45w7AuwCTomCugCGFv6aPtvMWoS5pmAFW7sfflX4a/MbZtYhkm9c+KvuWXhHdyX5ur8qqAt82F+F0wefA1uAt5xz5e6vCH4eg6kL/Pk83g/cDBSUsz7k+yuaAz3QT6rSP3mDGRNqwbzna0Cac64TsJBffgr7zY/9FYxP8fpTZAEPAHMi9cZmVhd4GbjBObe79OoAL4nI/qqkLl/2l3PuqHOuM5AKdDOzM0sN8WV/BVFXxD+PZjYI2OKcW1bRsADLTmh/RXOg5wMlf5KmAj+UN8bMEoCTCf+v9pXW5Zzb7pw7WPj0CaBrmGsKVjD7NOKcc7uLfm12zr0OJJpZ43C/r5kl4oXmi865VwIM8WV/VVaXX/urxPvvBN4BBpRa5cfnsdK6fPo89gIGm9k6vGnZc83shVJjQr6/ojnQlwBtzCzdzJLwThrMKzVmHnBZ4eNhwNuu8AyDn3WVmmcdjDcPGg3mAaMLr97oAexyzv3od1FmdmrR3KGZdcP7d7k9zO9pwFNAnnPu3nKGRXx/BVOXT/srxcwaFD6uBZwHrCo1LOKfx2Dq8uPz6Jz7q3Mu1TmXhpcRbzvnLi01LOT7K+FEXhxOzrkjZnYtsADvypKnnXMrzOwfwFLn3Dy8f/jPm9lavJ9sI6KkruvNbDBwpLCuy8NdF4CZTce7AqKxmeUD/4N3kgjn3KPA63hXbqwF9gNjoqSuYcDVZnYE+BkYEYEfzL2AUcCXhfOvALcALUvU5cf+CqYuP/ZXM+BZM6uJ9wNklnNuvt+fxyDr8uXzGEi495du/RcRiRPRPOUiIiJVoEAXEYkTCnQRkTihQBcRiRMKdBGROKFAFxGJEwp0EZE48f8B/vNGkCLaXVkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_accur = np.array([score_nn[1], score_nn10[1], score_nn15[1], score_nn20[1], score_nn50[1]])\n",
    "cn_accur = np.array([score_cn[1], score_cn10[1], score_cn15[1], score_cn20[1], score_cn50[1]])\n",
    "plt.plot(nn_accur, label='NN Accuracy', color='b')\n",
    "plt.plot(cn_accur, label='CN Accuracy', color='orange')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9835, 0.1128, 0.1135, 0.1138, 0.1135])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84490001, 0.1135    , 0.1135    , 0.1135    , 0.1135    ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_accur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
